{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiLayerPerceptron",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnQIrBlOaCBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive; \n",
        "drive.mount(\"/content/drive/\")\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/DL\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifyKS9aKAbbw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "73f87196-ad55-4d33-f4cd-9bd5d8be7da7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plui0PjYblWx",
        "colab_type": "text"
      },
      "source": [
        "**add correct path**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5iOaRCMb2p5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/DL\")\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import MNISTDataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CWHaeRHcD56",
        "colab_type": "text"
      },
      "source": [
        "**Using bias from a random normal distribution with given standard deviation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tQ-FnsVrJTd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "d4bed177-5f57-486f-ed85-13f5cd73870d"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "plt.imshow(train_images[0], cmap=\"Greys_r\")\n",
        "\n",
        "data = MNISTDataset(train_images.reshape([-1, 784]), train_labels, \n",
        "                    test_images.reshape([-1, 784]), test_labels,\n",
        "                    batch_size=128)\n",
        "# W = tf.Variable(np.zeros([784, 10]).astype(np.float32))\n",
        "# b = tf.Variable(np.zeros(10, dtype=np.float32))\n",
        "train_steps = 10000\n",
        "learning_rate = 0.01\n",
        "feature_size = 784\n",
        "num_neurons = 512\n",
        "num_classes = 10 \n",
        "Bias = {\"b0\":tf.Variable(tf.random.normal([num_neurons],stddev = .1)),\n",
        "        \"b1\":tf.Variable(tf.random.normal([num_classes],stddev = .1))\n",
        "        }\n",
        "W = {\"W0\":tf.Variable(tf.random.normal([feature_size,num_neurons],stddev=.1)),\n",
        "     \"W1\":tf.Variable(tf.random.normal([num_neurons,10],stddev=.1)),\n",
        "    }\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKMIPBEX4gaD+C/r8nCyCGma/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0wsHrh9bxQg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Training using gradient tape with an input layer an output layer and an Hiddenlayer with Relu activation.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lYnr4l0DCSm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05186ddb-4181-44d8-81e8-0720ac23c7a2"
      },
      "source": [
        "for step in range(train_steps):\n",
        "    img_batch, lbl_batch = data.next_batch()\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        \n",
        "        input_layer = tf.matmul(img_batch, W['W0']) +Bias['b0']\n",
        "        hidden_layer = tf.nn.relu(input_layer)\n",
        "        output_layer = (tf.matmul(hidden_layer,W['W1']+Bias['b1']))\n",
        "        xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            logits=output_layer, labels=lbl_batch))\n",
        "        \n",
        "\n",
        "    grads = tape.gradient(xent, [Bias['b1'],W['W0'],Bias['b0'],W['W1']])\n",
        "    \n",
        "    Bias['b1'].assign_sub(learning_rate * tf.cast(grads[0],tf.float32))\n",
        "\n",
        "    W['W0'].assign_sub(learning_rate * grads[1])\n",
        "    Bias['b0'].assign_sub(learning_rate * grads[2])\n",
        "    W['W1'].assign_sub(learning_rate * grads[3])\n",
        "         \n",
        "    if not step % 100:\n",
        "        preds = tf.argmax(output_layer, axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch),\n",
        "                             tf.float32))\n",
        "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 33.00373077392578 Accuracy: 0.0703125\n",
            "Loss: 1.9820148944854736 Accuracy: 0.3359375\n",
            "Loss: 1.5133476257324219 Accuracy: 0.609375\n",
            "Loss: 1.2679803371429443 Accuracy: 0.703125\n",
            "Loss: 1.0363683700561523 Accuracy: 0.703125\n",
            "Starting new epoch...\n",
            "Loss: 0.691347599029541 Accuracy: 0.828125\n",
            "Loss: 0.6502552032470703 Accuracy: 0.828125\n",
            "Loss: 0.5786261558532715 Accuracy: 0.8515625\n",
            "Loss: 0.5692861080169678 Accuracy: 0.8203125\n",
            "Loss: 0.5730807781219482 Accuracy: 0.8515625\n",
            "Starting new epoch...\n",
            "Loss: 0.8507442474365234 Accuracy: 0.71875\n",
            "Loss: 0.5675575137138367 Accuracy: 0.8359375\n",
            "Loss: 0.49967095255851746 Accuracy: 0.84375\n",
            "Loss: 0.42704057693481445 Accuracy: 0.828125\n",
            "Loss: 0.4887896180152893 Accuracy: 0.8515625\n",
            "Starting new epoch...\n",
            "Loss: 0.2970004677772522 Accuracy: 0.9375\n",
            "Loss: 0.520378589630127 Accuracy: 0.875\n",
            "Loss: 0.38044577836990356 Accuracy: 0.890625\n",
            "Loss: 0.42373180389404297 Accuracy: 0.8828125\n",
            "Starting new epoch...\n",
            "Loss: 0.32233744859695435 Accuracy: 0.90625\n",
            "Loss: 0.3837887644767761 Accuracy: 0.875\n",
            "Loss: 0.3105613589286804 Accuracy: 0.90625\n",
            "Loss: 0.418057918548584 Accuracy: 0.8984375\n",
            "Loss: 0.3310159742832184 Accuracy: 0.9140625\n",
            "Starting new epoch...\n",
            "Loss: 0.36109769344329834 Accuracy: 0.859375\n",
            "Loss: 0.35934311151504517 Accuracy: 0.890625\n",
            "Loss: 0.3038673996925354 Accuracy: 0.8984375\n",
            "Loss: 0.2772041857242584 Accuracy: 0.9140625\n",
            "Loss: 0.39623862504959106 Accuracy: 0.875\n",
            "Starting new epoch...\n",
            "Loss: 0.33513298630714417 Accuracy: 0.90625\n",
            "Loss: 0.2780781388282776 Accuracy: 0.9140625\n",
            "Loss: 0.3845251798629761 Accuracy: 0.8828125\n",
            "Loss: 0.24797239899635315 Accuracy: 0.9296875\n",
            "Starting new epoch...\n",
            "Loss: 0.26883772015571594 Accuracy: 0.9375\n",
            "Loss: 0.2774693965911865 Accuracy: 0.921875\n",
            "Loss: 0.20499534904956818 Accuracy: 0.9375\n",
            "Loss: 0.32100290060043335 Accuracy: 0.8984375\n",
            "Loss: 0.25606006383895874 Accuracy: 0.921875\n",
            "Starting new epoch...\n",
            "Loss: 0.2894795536994934 Accuracy: 0.90625\n",
            "Loss: 0.33181965351104736 Accuracy: 0.8671875\n",
            "Loss: 0.3283165693283081 Accuracy: 0.890625\n",
            "Loss: 0.25475746393203735 Accuracy: 0.9140625\n",
            "Loss: 0.26096299290657043 Accuracy: 0.8984375\n",
            "Starting new epoch...\n",
            "Loss: 0.3928585648536682 Accuracy: 0.875\n",
            "Loss: 0.18123561143875122 Accuracy: 0.96875\n",
            "Loss: 0.22998689115047455 Accuracy: 0.9375\n",
            "Loss: 0.27697548270225525 Accuracy: 0.90625\n",
            "Starting new epoch...\n",
            "Loss: 0.23590439558029175 Accuracy: 0.921875\n",
            "Loss: 0.35796061158180237 Accuracy: 0.8828125\n",
            "Loss: 0.16146710515022278 Accuracy: 0.9765625\n",
            "Loss: 0.329668790102005 Accuracy: 0.90625\n",
            "Loss: 0.30702441930770874 Accuracy: 0.90625\n",
            "Starting new epoch...\n",
            "Loss: 0.4193194508552551 Accuracy: 0.8671875\n",
            "Loss: 0.3406214416027069 Accuracy: 0.890625\n",
            "Loss: 0.28614896535873413 Accuracy: 0.90625\n",
            "Loss: 0.19348126649856567 Accuracy: 0.9296875\n",
            "Loss: 0.2528587579727173 Accuracy: 0.9375\n",
            "Starting new epoch...\n",
            "Loss: 0.18778209388256073 Accuracy: 0.9375\n",
            "Loss: 0.2830752432346344 Accuracy: 0.9296875\n",
            "Loss: 0.2221629023551941 Accuracy: 0.921875\n",
            "Loss: 0.26340174674987793 Accuracy: 0.921875\n",
            "Starting new epoch...\n",
            "Loss: 0.1991860568523407 Accuracy: 0.9375\n",
            "Loss: 0.2261149287223816 Accuracy: 0.9375\n",
            "Loss: 0.3200652599334717 Accuracy: 0.890625\n",
            "Loss: 0.23491114377975464 Accuracy: 0.9375\n",
            "Loss: 0.17159351706504822 Accuracy: 0.953125\n",
            "Starting new epoch...\n",
            "Loss: 0.27469900250434875 Accuracy: 0.9296875\n",
            "Loss: 0.21969664096832275 Accuracy: 0.9296875\n",
            "Loss: 0.20934562385082245 Accuracy: 0.9375\n",
            "Loss: 0.3078722059726715 Accuracy: 0.875\n",
            "Loss: 0.1180107370018959 Accuracy: 0.984375\n",
            "Starting new epoch...\n",
            "Loss: 0.23310475051403046 Accuracy: 0.9296875\n",
            "Loss: 0.1521596610546112 Accuracy: 0.9453125\n",
            "Loss: 0.09811650216579437 Accuracy: 0.9765625\n",
            "Loss: 0.2883092164993286 Accuracy: 0.9375\n",
            "Loss: 0.25847822427749634 Accuracy: 0.9296875\n",
            "Starting new epoch...\n",
            "Loss: 0.15498267114162445 Accuracy: 0.953125\n",
            "Loss: 0.322153776884079 Accuracy: 0.875\n",
            "Loss: 0.2285480946302414 Accuracy: 0.9375\n",
            "Loss: 0.17919668555259705 Accuracy: 0.9453125\n",
            "Starting new epoch...\n",
            "Loss: 0.25932547450065613 Accuracy: 0.8984375\n",
            "Loss: 0.26974648237228394 Accuracy: 0.9296875\n",
            "Loss: 0.17159777879714966 Accuracy: 0.9765625\n",
            "Loss: 0.1662026047706604 Accuracy: 0.953125\n",
            "Loss: 0.1230560839176178 Accuracy: 0.9609375\n",
            "Starting new epoch...\n",
            "Loss: 0.20572590827941895 Accuracy: 0.9375\n",
            "Loss: 0.2707308828830719 Accuracy: 0.921875\n",
            "Loss: 0.20581281185150146 Accuracy: 0.921875\n",
            "Loss: 0.13407480716705322 Accuracy: 0.9609375\n",
            "Loss: 0.08349409699440002 Accuracy: 0.9765625\n",
            "Starting new epoch...\n",
            "Loss: 0.28047630190849304 Accuracy: 0.921875\n",
            "Loss: 0.17863760888576508 Accuracy: 0.9609375\n",
            "Loss: 0.08585938811302185 Accuracy: 0.984375\n",
            "Loss: 0.22852297127246857 Accuracy: 0.9375\n",
            "Starting new epoch...\n",
            "Loss: 0.14722953736782074 Accuracy: 0.9453125\n",
            "Loss: 0.31170812249183655 Accuracy: 0.9140625\n",
            "Loss: 0.1556721329689026 Accuracy: 0.953125\n",
            "Loss: 0.1527457982301712 Accuracy: 0.96875\n",
            "Loss: 0.16042374074459076 Accuracy: 0.953125\n",
            "Starting new epoch...\n",
            "Loss: 0.12420891225337982 Accuracy: 0.96875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yHVR66ncmDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}